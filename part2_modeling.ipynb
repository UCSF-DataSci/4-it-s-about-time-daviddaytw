{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Time Series Modeling\n",
    "\n",
    "In this notebook, you will implement functions to extract features from time series data and build ARIMA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction\n",
    "\n",
    "Implement the `extract_time_series_features` function to calculate rolling window features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def extract_time_series_features(data, window_size=60):\n",
    "    \"\"\"Extract rolling window features from time series data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Preprocessed physiological data\n",
    "    window_size : int\n",
    "        Size of the rolling window in seconds\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing extracted features for each signal\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store features\n",
    "    features = {}\n",
    "    \n",
    "    # Process each signal column\n",
    "    for column in data.columns:\n",
    "        # Skip any non-numeric columns\n",
    "        if not pd.api.types.is_numeric_dtype(data[column]):\n",
    "            continue\n",
    "            \n",
    "        signal = data[column]\n",
    "        \n",
    "        # Basic rolling statistics\n",
    "        rolling_mean = signal.rolling(f'{window_size}s').mean()\n",
    "        rolling_std = signal.rolling(f'{window_size}s').std()\n",
    "        rolling_min = signal.rolling(f'{window_size}s').min()\n",
    "        rolling_max = signal.rolling(f'{window_size}s').max()\n",
    "        \n",
    "        # Calculate range\n",
    "        rolling_range = rolling_max - rolling_min\n",
    "        \n",
    "        # Calculate median and quantiles\n",
    "        rolling_median = signal.rolling(f'{window_size}s').median()\n",
    "        rolling_q25 = signal.rolling(f'{window_size}s').quantile(0.25)\n",
    "        rolling_q75 = signal.rolling(f'{window_size}s').quantile(0.75)\n",
    "        \n",
    "        # Calculate IQR\n",
    "        rolling_iqr = rolling_q75 - rolling_q25\n",
    "        \n",
    "        # Calculate skewness and kurtosis\n",
    "        rolling_skew = signal.rolling(f'{window_size}s').apply(lambda x: pd.Series(x).skew())\n",
    "        rolling_kurt = signal.rolling(f'{window_size}s').apply(lambda x: pd.Series(x).kurt())\n",
    "        \n",
    "        # Function to compute lag-1 autocorrelation for a window\n",
    "        def compute_autocorr(x):\n",
    "            if len(x) < 2 or np.all(x == x[0]):\n",
    "                return np.nan\n",
    "            try:\n",
    "                acf_result = acf(x, nlags=1, fft=False)\n",
    "                return acf_result[1]  # lag-1 autocorrelation\n",
    "            except:\n",
    "                return np.nan\n",
    "        \n",
    "        # Calculate lag-1 autocorrelation\n",
    "        rolling_autocorr = signal.rolling(f'{window_size}s').apply(compute_autocorr)\n",
    "        \n",
    "        # Store features with column name prefix\n",
    "        features[f'{column}_mean'] = rolling_mean\n",
    "        features[f'{column}_std'] = rolling_std\n",
    "        features[f'{column}_min'] = rolling_min\n",
    "        features[f'{column}_max'] = rolling_max\n",
    "        features[f'{column}_range'] = rolling_range\n",
    "        features[f'{column}_median'] = rolling_median\n",
    "        features[f'{column}_q25'] = rolling_q25\n",
    "        features[f'{column}_q75'] = rolling_q75\n",
    "        features[f'{column}_iqr'] = rolling_iqr\n",
    "        features[f'{column}_skew'] = rolling_skew\n",
    "        features[f'{column}_kurt'] = rolling_kurt\n",
    "        features[f'{column}_autocorr'] = rolling_autocorr\n",
    "    \n",
    "    # Combine all features into a single DataFrame\n",
    "    features_df = pd.DataFrame(features, index=data.index)\n",
    "    \n",
    "    # Drop NaN values that occur at the beginning due to the window size\n",
    "    features_df = features_df.dropna()\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARIMA Modeling\n",
    "\n",
    "Implement the `build_arima_model` function to fit ARIMA models and generate diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "def build_arima_model(series, order=(1,1,1), output_dir='plots'):\n",
    "    \"\"\"Fit an ARIMA model to the time series and generate diagnostic plots.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Time series data to model\n",
    "    order : tuple\n",
    "        (p,d,q) order of the ARIMA model\n",
    "    output_dir : str\n",
    "        Directory to save diagnostic plots\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    statsmodels.tsa.arima.model.ARIMAResults\n",
    "        Fitted ARIMA model\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Fit ARIMA model\n",
    "    model = ARIMA(series, order=order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # 2. Generate diagnostic plots\n",
    "    \n",
    "    # Model fit plot - actual vs fitted values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(series, label='Original Data')\n",
    "    plt.plot(model_fit.fittedvalues, color='red', label='Fitted Values')\n",
    "    plt.title(f'ARIMA{order} - Original vs Fitted Values')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/model_fit.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Residuals plot\n",
    "    residuals = pd.DataFrame(model_fit.resid)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 8))\n",
    "    \n",
    "    # Residuals time plot\n",
    "    residuals.plot(ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Residuals')\n",
    "    \n",
    "    # Residuals histogram\n",
    "    residuals.plot(kind='hist', density=True, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Residuals Distribution')\n",
    "    \n",
    "    # Residuals ACF\n",
    "    plot_acf(residuals, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Residuals ACF')\n",
    "    \n",
    "    # Residuals PACF\n",
    "    plot_pacf(residuals, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Residuals PACF')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/residuals_diagnostics.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Forecast plot\n",
    "    # Generate forecasts for the next 10 periods\n",
    "    forecast_steps = 10\n",
    "    forecast = model_fit.get_forecast(steps=forecast_steps)\n",
    "    forecast_values = forecast.predicted_mean\n",
    "    conf_int = forecast.conf_int()\n",
    "    \n",
    "    # Create a forecast plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(series, label='Original Data')\n",
    "    \n",
    "    # Create a date range for the forecast\n",
    "    if isinstance(series.index, pd.DatetimeIndex):\n",
    "        # If the index is a DatetimeIndex, extend it properly\n",
    "        forecast_index = pd.date_range(start=series.index[-1], periods=forecast_steps+1, freq=series.index.freq)[1:]\n",
    "    else:\n",
    "        # If the index is numeric, just extend it\n",
    "        forecast_index = np.arange(len(series), len(series) + forecast_steps)\n",
    "    \n",
    "    # Plot the forecast\n",
    "    plt.plot(forecast_index, forecast_values, color='red', label='Forecast')\n",
    "    plt.fill_between(forecast_index, \n",
    "                    conf_int.iloc[:, 0], \n",
    "                    conf_int.iloc[:, 1], \n",
    "                    color='pink', alpha=0.3, label='95% Confidence Interval')\n",
    "    \n",
    "    plt.title(f'ARIMA{order} Forecast')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/forecast.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Return the fitted model\n",
    "    return model_fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
